
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Luigi Pipelines &#8212; GSI Crawler 1.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="luigi-pipelines">
<h1>Luigi Pipelines<a class="headerlink" href="#luigi-pipelines" title="Permalink to this headline">¶</a></h1>
<p>We use Luigi as orchestrator to build pipelines through our search and indexing system and the analytic services, in order to facilitate analysis. It handles dependency resolution, workflow management, visualization etc. Luigi needs a script describing the pipeline to follow.</p>
<p>These scripts describe tasks. This tasks has a execution sequence, i.e. the final task depend on the others. This means that for running the script you only need to call the final task.</p>
<p>For following steps, the example used is sefarad.py (this script is located inside Luigi folder)</p>
<p>In our example tasks are: FetchDataTask, SenpyTask and Elasticsearch.</p>
<ul class="simple">
<li><strong>FetchDataTask</strong>: The main goal of this task is to read the JSON file.</li>
</ul>
<div class="code python highlight-default"><div class="highlight"><pre><span></span> <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Writes data in JSON format into the task&#39;s output target.</span>
<span class="sd">The data objects have the following attributes:</span>
<span class="sd">* `_id` is the default Elasticsearch id field,</span>
<span class="sd">* `text`: the text,</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1">#today = datetime.date.today()</span>
<span class="n">file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">j</span><span class="p">:</span>
        <span class="n">i</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span> <span class="c1">#necessary for elasticsearch index</span>
<span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">output</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="n">output</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>SenpyTask</strong>: This task loads data fetched with previous task and send it to Senpy tool in order to analyse data retrieved and check sentiments expressed.</li>
</ul>
<div class="code python highlight-default"><div class="highlight"><pre><span></span> <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Send data to Senpy tool and retrieve it analyzed. Store data in a json file.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">output</span><span class="p">:</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">infile</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">j</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;http://test.senpy.cluster.gsi.dit.upm.es/api/?algo=sentiment-tass&amp;i=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
            <span class="n">response_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="n">i</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span>
            <span class="c1">#i[&quot;analysis&quot;] = response_json</span>
            <span class="n">i</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_json</span><span class="p">[</span><span class="s2">&quot;entries&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;sentiments&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;marl:hasPolarity&quot;</span><span class="p">]</span>
            <span class="n">i</span><span class="p">[</span><span class="s2">&quot;polarity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_json</span><span class="p">[</span><span class="s2">&quot;entries&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;sentiments&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;marl:polarityValue&quot;</span><span class="p">]</span>
            <span class="n">output</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="c1">#print(i)</span>
            <span class="n">output</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>Elasticsearch</strong>: This task loads JSON data contained in the file produced in the previous step into an Elasticsearch index.</li>
</ul>
<div class="section" id="running-luigi-pipelines">
<h2>Running Luigi pipelines<a class="headerlink" href="#running-luigi-pipelines" title="Permalink to this headline">¶</a></h2>
<p>This command is for running your pipelines. You have to introduce your script name in modules and the end task of your script.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ sudo docker-compose <span class="nb">exec</span> luigi python -m luigi --module &lt;your-script-name&gt; &lt;your-final-task&gt; --index &lt;your-elasticsearch-index&gt; --doc-type &lt;your-elasticsearch-doctype&gt; -- filename &lt;your .json path&gt;
</pre></div>
</div>
<p>In our example:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ sudo docker-compose <span class="nb">exec</span> luigi python -m luigi --module add_tweets Elasticsearch --index tourpedia --doc-type places --filename add_demo.json
</pre></div>
</div>
<p>Create your own pipelines like in the example and add them to Luigi folder is also necessary to add your JSON file to this folder, run them with the same command explained above.</p>
</div>
<div class="section" id="cron-luigi-pipeline">
<h2>Cron Luigi Pipeline<a class="headerlink" href="#cron-luigi-pipeline" title="Permalink to this headline">¶</a></h2>
<p>This cron job is designed for sentiment analysis in Twitter every day. This will update your dashboard content automatically.
For using this cron pipeline is necessary to change docker-compose.yml file adding your own enviroment variables:</p>
<p>There are the following parameters available:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you set LUIGI_AUTO_ENABLED to False the other parameters are not needed.</p>
</div>
<div class="code yaml highlight-default"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">LUIGI_AUTO_ENABLED</span><span class="o">=</span><span class="kc">True</span> <span class="c1">#Set this to True if you want to start Twitter analysis pipeline as a cron job</span>
<span class="o">-</span> <span class="n">CONSUMER_KEY</span><span class="o">=</span><span class="p">{</span><span class="n">your</span> <span class="n">twitter</span> <span class="n">CONSUMER_KEY</span> <span class="n">goes</span> <span class="n">here</span><span class="p">}</span>
<span class="o">-</span> <span class="n">CONSUMER_SECRET</span><span class="o">=</span><span class="p">{</span><span class="n">your</span> <span class="n">twitter</span> <span class="n">CONSUMER_SECRET</span> <span class="n">goes</span> <span class="n">here</span><span class="p">}</span>
<span class="o">-</span> <span class="n">ACCESS_TOKEN</span><span class="o">=</span><span class="p">{</span><span class="n">your</span> <span class="n">twitter</span> <span class="n">ACCESS_TOKEN</span> <span class="n">goes</span> <span class="n">here</span><span class="p">}</span>
<span class="o">-</span> <span class="n">ACCESS_TOKEN_SECRET</span><span class="o">=</span><span class="p">{</span><span class="n">your</span> <span class="n">twitter</span> <span class="n">ACCESS_TOKEN_SECRET</span> <span class="n">goes</span> <span class="n">here</span><span class="p">}</span>
<span class="o">-</span> <span class="n">EMAIL</span><span class="o">=</span><span class="p">{</span><span class="n">email</span> <span class="n">addres</span> <span class="k">for</span> <span class="n">Luigi</span> <span class="n">notifications</span><span class="p">}</span>
<span class="o">-</span> <span class="n">SMTP_HOST</span><span class="o">=</span><span class="p">{</span><span class="n">your</span> <span class="n">SMTP</span> <span class="n">server</span><span class="p">}</span>
<span class="o">-</span> <span class="n">SMTP_PORT</span><span class="o">=</span><span class="p">{</span><span class="n">your</span> <span class="n">SMTP</span> <span class="n">server</span> <span class="n">port</span><span class="p">}</span>
<span class="o">-</span> <span class="n">SEARCH_QUERY</span><span class="o">=</span><span class="p">{</span><span class="n">twitter</span> <span class="n">hashtag</span> <span class="ow">or</span> <span class="n">user</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="n">track</span><span class="p">}</span>
<span class="o">-</span> <span class="n">INDEX</span><span class="o">=</span><span class="p">{</span><span class="n">elasticsearch</span> <span class="n">index</span> <span class="n">to</span> <span class="n">store</span> <span class="n">your</span> <span class="n">data</span><span class="p">}</span>
<span class="o">-</span> <span class="n">DOC_TYPE</span><span class="o">=</span><span class="p">{</span><span class="n">elasticsearch</span> <span class="n">data</span> <span class="n">doctype</span><span class="p">}</span>
</pre></div>
</div>
<p>Mail configuration is not required but is highly recommended to be notified when a task fails.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Please visit, <a class="reference external" href="https://apps.twitter.com/">https://apps.twitter.com/</a> to create your app if you don’t have your Twitter credentials.</p>
</div>
<p>After your configuration is completed, run Sefarad image again:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>$ sudo docker-compose up
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If your get a connection error: build the image again and then run it.</p>
</div>
<p>Finally, check your elasticsearch index entered above. If you want to use this new data in your dashboard just update your index and doc-type references in your HTML dashboard file.</p>
</div>
<div class="section" id="luigi-service">
<h2>Luigi Service<a class="headerlink" href="#luigi-service" title="Permalink to this headline">¶</a></h2>
<p>In order to queue new crawling requests, a Python Flask server has been developed to stack these tasks using Luigi. The service enables to send basic input parameters, such as the url of the website desired to be scrapped, the analysis type and the elasticSearch basic information. The remote service processes all these data and creates performs the pipeline in background, fetching, analyzing and finally saving the data. The service returns the id and index where has been stored in elasticSearch.</p>
<p>To explain more in deepth this work-flow process, we are going to briefly introduce an illustrative example.</p>
<p>The case study explained is: “<strong>Perform a sentiment analysis for HP Wired USB Keyboard from Amazon website</strong>”. The pipeline architecture is represented below:</p>
<a class="reference internal image-reference" href="_images/picLuigi.png"><img alt="_images/picLuigi.png" class="align-center" src="_images/picLuigi.png" style="width: 960.0px; height: 320.0px;" /></a>
<p>The service receives the new task input parameter, which are the url of the product from where the reviews will be extracted, the analysis that is going to be performed and the platform where is hosted the product. The service creates a new elasticSearch task and the execution begins. Once the result is saved in elasticSearch, the API call returns the destination where its stored so the user can retrieve it. This service is only available for Amazon and Foursquare platforms, and is currently used by the GSICrawler dashboard.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo-gsi-crawler.png" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gsi-upm&repo=gsicrawler&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gsicrawler.html">What is GSI Crawler?</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Getting started</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Antonio F. Llamas.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/pipelines.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/gsi-upm/gsicrawler" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>